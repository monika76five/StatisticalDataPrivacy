install.packages("rstan")
install.packages("rstan")
install.packages("rstan")
download.file("http://www.openintro.org/stat/data/bdims.RData", destfile = "bdims.RData")
load("bdims.RData")
View(bdims)
names(bdims)
fems <- bdims[bdims$sex == 0,]
View(fems)
table(fems$sex)
hist(fems$hgt)
plot(fems$hgt)
warnings()
require(devtools)
install.packages("devtools")
library(ggplot2)
qplot(mpg, wt, data=mtcars)
load("~/Dropbox/BLS work/CE project/CE project 5/simulation studies/Poisson/mu50.RData")
#other libraries
library(sf) #load before LS2Wstat
library(LS2Wstat)
library(tidyverse)
library(Rfast)
library(superheat)
library(ggthemes)
cbPalette_withdata <- c("#0072B2", "#999999",  "#E69F00", "#56B4E9",  "#009E73", "#CC79A7", "#D55E00",  "#F0E442")
cbPalette_withoutdata <- c("#999999",  "#E69F00", "#56B4E9",  "#009E73", "#CC79A7", "#D55E00",  "#F0E442")
Lbounds = cbind(loglike_notw$log_ratio_data,
loglike_w_LW$log_ratio_data,
loglike_w_CW_final$log_ratio_data,
loglike_w_SW_final$log_ratio_data) %>% as_tibble()
names(Lbounds) = c("Unweighted", "LW", "CW","SW")
Lbounds_long = reshape2::melt(Lbounds)
plot_L <- ggplot(Lbounds_long, aes(x = variable, y = value, fill = variable, color = variable)) +
geom_violin(trim=TRUE, alpha = 0.3) +
scale_colour_manual(values = cbPalette_withoutdata) + scale_fill_manual(values = cbPalette_withoutdata) +
theme_bw(base_size = 15)   +
theme(legend.position = "none")  +
ylab("Lipschitz Bounds") + xlab("")  #+ ylim(0, 1)
plot_L
2*(log(5)+3)
install.packages("mdsr")
library(tidyverse)
cbPalette <- c("#E69F00", "#56B4E9", "#999999", "#009E73", "#F0E442",
"#0072B2", "#D55E00", "#CC6666", "#9999CC")
sampling_rate_seq <- seq(0.001, 1, by = 0.001)
df <- data.frame(c(log(1 + 1 / sampling_rate_seq * (exp(0.1) - 1)),
log(1 + 1 / sampling_rate_seq * (exp(0.5) - 1)),
log(1 + 1 / sampling_rate_seq * (exp(1) - 1))))
names(df) <- c("epsilon_s")
df$epsilon <- c(rep(0.1, length(sampling_rate_seq)),
rep(0.5, length(sampling_rate_seq)),
rep(1, length(sampling_rate_seq)))
df$epsilon <- factor(df$epsilon, levels = c(0.1, 0.5, 1))
df$sampling_rate <- rep(sampling_rate_seq, 3)
ggplot(df, aes(y = epsilon_s, x = sampling_rate, colour = epsilon, shape = epsilon)) +
geom_line(aes(linetype = epsilon, color = epsilon), size = 1) +
scale_colour_manual(name = "epsilon",
labels = c(expression(paste(epsilon, " = 0.1")),
expression(paste(epsilon, " = 0.5")),
expression(paste(epsilon, " = 1"))),
values = cbPalette) +
scale_linetype_manual(name = "epsilon",
labels = c(expression(paste(epsilon, " = 0.1")),
expression(paste(epsilon, " = 0.5")),
expression(paste(epsilon, " = 1"))),
values = 1:3) +
theme_bw(base_size = 23)   +
theme(legend.position=c(0.8, 0.8), legend.title = element_blank()) +
ylim(0, 8) +
xlab("sampling rate") +
ylab(expression(paste(epsilon, "_n")))
ggplot(df, aes(y = epsilon_s, x = sampling_rate, colour = epsilon, shape = epsilon)) +
geom_line(aes(linetype = epsilon, color = epsilon), size = 1) +
scale_colour_manual(name = "epsilon",
labels = c(expression(paste(epsilon, " = 0.1")),
expression(paste(epsilon, " = 0.5")),
expression(paste(epsilon, " = 1"))),
values = cbPalette) +
scale_linetype_manual(name = "epsilon",
labels = c(expression(paste(epsilon, " = 0.1")),
expression(paste(epsilon, " = 0.5")),
expression(paste(epsilon, " = 1"))),
values = 1:3) +
theme_bw(base_size = 23)   +
theme(legend.position=c(0.8, 0.8), legend.title = element_blank()) +
ylim(0, 8) +
xlab("sampling rate") +
ylab(expression(paste(epsilon[n])))
set.seed(613)
## first 10 to enroll; second 10 to waitlist; follow the order
sample(seq(1:35), size = 20, replace = FALSE)
X1= rmultinom(n = 1000, size = 3, prob = c(0.3, 0.3, 0.4))
View(X1)
?rmultinom
X1= rmultinom(n = 1000, size = 1, prob = c(0.3, 0.3, 0.4))
View(X1)
X1= which(rmultinom(n = 1000, size = 1, prob = c(0.3, 0.3, 0.4)) == 1)
X1
which(rmultinom(n = 1, size = 1, prob = c(0.3, 0.3, 0.4)) == 1)
which(rmultinom(n = 1, size = 1, prob = c(0.3, 0.3, 0.4)) == 1)
which(rmultinom(n = 1, size = 1, prob = c(0.3, 0.3, 0.4)) == 1)
n <- 1000
X1 <- rep(NA, n)
for (i in 1:n){
X1[i] <- which(rmultinom(n = 1, size = 1, prob = c(0.3, 0.3, 0.4)) == 1)
}
X1
require(NPBayesImputeCat)
install.packages("rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
library(Rcpp)
install.packages("NPBayesImputeCat")
library(NPBayesImputeCat)
data("ss16pusa_sample_nozeros_miss")
X <- ss16pusa_sample_nozeros_miss
p <- ncol(X)
for (j in 1:p){
X[,j] <- as.factor(X[,j])
}
model <- CreateModel(X = X,
MCZ = NULL,
K = 30,
Nmax = 0,
aalpha = 0.25,
balpha = 0.25,
seed = 456)
model$Run(burnin = 2,
iter = 5,
thinning = 1,
silent = FALSE)
model$Run(burnin = 5,
iter = 10,
thinning = 1,
silent = FALSE)
library(NPBayesImputeCat)
data("ss16pusa_sample_nozeros_miss")
X <- ss16pusa_sample_nozeros_miss
p <- ncol(X)
for (j in 1:p){
X[,j] <- as.factor(X[,j])
}
model <- CreateModel(X = X,
MCZ = NULL,
K = 30,
Nmax = 0,
aalpha = 0.25,
balpha = 0.25,
seed = 456)
model$Run(burnin = 5,
iter = 10,
thinning = 1,
silent = FALSE)
library(NPBayesImputeCat)
###########################################
###########################################
######## Missing data applications ########
###########################################
###########################################
###########################################
######### without zeros ###################
###########################################
data("ss16pusa_sample_nozeros_miss")
X <- ss16pusa_sample_nozeros_miss
p <- ncol(X)
for (j in 1:p){
X[,j] <- as.factor(X[,j])
}
model <- CreateModel(X = X,
MCZ = NULL,
K = 30,
Nmax = 0,
aalpha = 0.25,
balpha = 0.25,
seed = 456)
model$Run(burnin = 2,
iter = 5,
thinning = 1,
silent = FALSE)
model <- CreateModel(X = X,
MCZ = NULL,
K = 80,
Nmax = 0,
aalpha = 0.25,
balpha = 0.25,
seed = 456)
model$Run(burnin = 2,
iter = 5,
thinning = 1,
silent = FALSE)
xcode-select --install
which git
remove.packages("NPBayesImputeCat")
install.packages("devtools")
library(devtools)
devtools::install_github(repo = "monika76five/NPBayesImputeCat")
devtools::install_github("monika76five/NPBayesImputeCat")
setwd("~/Dropbox/Vassar 2019-2022/Fall 2021/Intensive/lectures/Lecture 7 Methods for utility evaluation part 2")
knitr::opts_chunk$set(echo = TRUE)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
CEdata <- readr::read_csv(file = "CEdata.csv")
CEdata$LogIncome <- log(CEdata$Income)
CEdata$LogExpenditure <- log(CEdata$Expenditure)
library(brms)
SLR_ff <- stats::as.formula(LogExpenditure ~ 1 + LogIncome)
SLR_model <- stats::model.frame(SLR_ff, CEdata)
SLR_X <- data.frame(stats::model.matrix(SLR_ff, SLR_model))
SLR_fit <- brms::brm(data = CEdata,
family = gaussian,
LogExpenditure ~ 1 + LogIncome,
prior = c(prior(normal(0, 10), class = Intercept),
prior(normal(0, 10), class = b),
prior(cauchy(0, 1), class = sigma)),
iter = 5000,
warmup = 3000,
thin = 1,
chains = 1,
seed = 539)
post_SLR <- brms::posterior_samples(SLR_fit)
SLR_synthesize <- function(X, post_draws, index, n, seed){
set.seed(seed)
mean_Y <- as.matrix(X) %*%
t(data.matrix(post_draws[index, c("b_Intercept", "b_LogIncome")]))
synthetic_Y <- stats::rnorm(n, mean_Y, post_draws[index, "sigma"])
data.frame(X, synthetic_Y)
}
n <- nrow(CEdata)
m <- 20
SLR_synthetic_m_partial <- vector("list", m)
for (l in 1:m){
SLR_synthetic_one_partial <- SLR_synthesize(X = SLR_X,
post_draws = post_SLR,
index = 1980 + l,
n = n,
seed = m + l)
names(SLR_synthetic_one_partial) <- c("Intercept", "LogIncome", "LogExpenditure")
SLR_synthetic_one_partial$Expenditure <- exp(SLR_synthetic_one_partial$LogExpenditure)
SLR_synthetic_one_partial$Income <- exp(SLR_synthetic_one_partial$LogIncome)
SLR_synthetic_m_partial[[l]] <- SLR_synthetic_one_partial
}
setwd("~/Dropbox/Project Hang and Monika/simulations/D_Simulation_for_Revision_2021_10")
setwd("~/Dropbox/Vassar 2019-2022/Fall 2021/Intensive/lectures/Lecture 7 Methods for utility evaluation part 2")
