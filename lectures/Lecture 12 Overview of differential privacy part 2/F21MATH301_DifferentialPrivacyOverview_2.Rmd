---
title: Overview of Differential Privacy part 2
author: Jingchen (Monika) Hu 
institute: Vassar College
date: Statistical Data Privacy
output:
  beamer_presentation:
    includes:
      in_header: ../LectureStyle.tex
slide_level: 2
fontsize: 11pt
bibliography: ../book.bib
---


```{r setup, include=FALSE}
require(dplyr)
require(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

## Outline

\tableofcontents[hideallsubsections]

# Introduction

## Recap from overview part 1

- Key idea: add \textcolor{red}{noise} to the \textcolor{red}{output} of \textcolor{red}{statistics} made to \textcolor{red}{databases}

- Added noise is random; depends on a predetermined \textcolor{red}{privacy budget} and the type of statistics

- Two important implications:
    1. the added noise is positively related to the sensitivity
    2. the added noise is negatively related to the privacy budget

\pause 

- How to add noise then?

## Plan

- The Laplace Mechanism
    - a mechanism that satisfies $\epsilon-$differential privacy
    - adds noise from a Laplace distribution to the statistic output
    - the parameters of the corresponding Laplace distribution depend on the \textcolor{red}{sensitivity} ($\Delta f$) and the \textcolor{red}{privacy budget} ($\epsilon$)
    
- Properties of differential privacy
    - composition theorem
    - sequential composition
    - parallel composition
    - post-processing
    
# The Laplace Mechanism

## The Laplace distribution

- A random variable has a $\textrm{Laplace}(\mu, s)$ distribution if its probability density function is
\begin{eqnarray}
f(x \mid \mu, s) &=& \frac{1}{2s} \exp \left(-\frac{|x - \mu|}{s} \right)  \\
                &=& \frac{1}{2s}
                \begin{cases}
                \exp \left(-\frac{\mu - x}{s} \right) \,\,\, \text{if} \,\,\, x < \mu; \\
                \exp \left(-\frac{x - \mu}{s} \right) \,\,\, \text{if} \,\,\, x \geq \mu,
                \end{cases}
\end{eqnarray}
    - $\mu$ is a location parameter
    - $s > 0$ is a scale parameter
    - when $\mu = 0, b = 1$, the positive half-line is an exponential distribution scaled by $1/2$


## The Laplace distribution

- Like the normal distribution, the Laplace distribution is symmetric

- It is entered at its location parameter $\mu$

- The scale parameter $s$ controls its spread: larger $s$ indicates bigger spread

## The Laplace distribution

```{r message=FALSE, size = "footnotesize", eval = FALSE}
require(rmutil)
cbPalette <- c("#999999",  "#E69F00", "#56B4E9",  "#009E73", 
               "#CC79A7", "#D55E00",  "#F0E442", "#0072B2")
ggplot(data.frame(x = c(-10, 10)), aes(x)) + 
  stat_function(fun = dlaplace, args = list(m = 0, s = 0.1), 
                aes(color = "Laplace(0, 0.1)")) +
  stat_function(fun = dlaplace, args = list(m = 0, s = 0.5), 
                aes(color = "Laplace(0, 0.5)")) + 
  stat_function(fun = dlaplace, args = list(m = 0, s = 1), 
                aes(color = "Laplace(0, 1)")) +
  stat_function(fun = dlaplace, args = list(m = -5, s = 1), 
                aes(color = "Laplace(-5,1)")) +
  scale_colour_manual(values = cbPalette) + ylab("Density") +
  theme_bw(base_size = 10, base_family = "")
```

## The Laplace distribution

```{r fig.height = 3, fig.width = 4, fig.align = "center", size = "footnotesize", message = FALSE, echo = FALSE}
require(rmutil)
cbPalette <- c("#999999",  "#E69F00", "#56B4E9",  "#009E73", 
               "#CC79A7", "#D55E00",  "#F0E442", "#0072B2")
ggplot(data.frame(x = c(-10, 10)), aes(x)) + 
  stat_function(fun = dlaplace, args = list(m = 0, s = 0.1), 
                aes(color = "Laplace(0, 0.1)")) +
  stat_function(fun = dlaplace, args = list(m = 0, s = 0.5), 
                aes(color = "Laplace(0, 0.5)")) + 
  stat_function(fun = dlaplace, args = list(m = 0, s = 1), 
                aes(color = "Laplace(0, 1)")) +
  stat_function(fun = dlaplace, args = list(m = -5, s = 1), 
                aes(color = "Laplace(-5,1)")) +
  scale_colour_manual(values = cbPalette) + ylab("Density") +
  theme_bw(base_size = 10, base_family = "")
```

## The Laplace distribution vs the normal distribution

```{r message=FALSE, size = "footnotesize", eval = FALSE}
require(rmutil)
ggplot(data.frame(x = c(-10, 10)), aes(x)) + 
  stat_function(fun = dlaplace, args = list(m = 0, s = sqrt(1/2)), 
                aes(color = "Laplace(0, sqrt(1/2))")) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), 
                aes(color = "Normal(0, 1)")) +
  scale_colour_manual(values = cbPalette) + ylab("Density") +
  theme_bw(base_size = 10, base_family = "") 
```

## The Laplace distribution vs the normal distribution

```{r fig.height = 3, fig.width = 4, fig.align = "center", size = "footnotesize", message = FALSE, echo = FALSE}
require(rmutil)
ggplot(data.frame(x = c(-10, 10)), aes(x)) + 
  stat_function(fun = dlaplace, args = list(m = 0, s = sqrt(1/2)), 
                aes(color = "Laplace(0, sqrt(1/2))")) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), 
                aes(color = "Normal(0, 1)")) +
  scale_colour_manual(values = cbPalette) + ylab("Density") +
  theme_bw(base_size = 10, base_family = "") 
```


## Laplace noise for privacy protection

- The Laplace Mechanism adds noise to the output with $\epsilon-$differential privacy guarantee

- The noise is drawn from a Laplace distribution

- Two important implications:
    1. the added noise is positively related to the sensitivity ($\Delta f$)
    2. the added noise is negatively related to the privacy budget ($\epsilon$)
    
- Also know that:
    1. the sensitivity ($\Delta f$) is dependent on the database and the statistic
    2. the privacy budget ($\epsilon$) is independent of the database and the statistic 

## Laplace noise for privacy protection

- For given sensitivity $\Delta f$ and privacy budget $\epsilon$, the added noise to the output of a statistic sent to database ${\bf{x}}$, $X^*$ is drawn from a Laplace distribution with mean 0, and scale $\frac{\Delta f}{\epsilon}$:

\begin{equation}
X^* \sim \textrm{Laplace}\left(0, \frac{\Delta f}{\epsilon}\right)
\end{equation}

\pause

- The scale of a Laplace distribution controls its spread, and larger scale value indicates bigger spread

- If the added noise needs to be larger, we should draw it from a Laplace distribution with larger scale value, and vice versa 


## The scale $\frac{\Delta f}{\epsilon}$

\begin{equation*}
X^* \sim \textrm{Laplace}\left(0, \frac{\Delta f}{\epsilon}\right)
\end{equation*}

- The scale $\frac{\Delta f}{\epsilon}$ is the ratio of the $\ell_1-$sensitivity and the privacy budget

- Connection to the two implications?
    1. the added noise is positively related to the sensitivity ($\Delta f$)
    2. the added noise negatively related to the privacy budget ($\epsilon$)
    
## The Laplace Mechanism

- Formally, given any function $f: \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathbb{R}^k$, the Laplace mechanism is defined as

\begin{equation}
\mathcal{M}_{L}({\bf{x}}, f(\cdot), \epsilon) = f({\bf{x}}) + (X_1^*, \cdots, X_k^*), 
\end{equation}
where $X_i^*$ are *i.i.d.* random variables drawn from $\textrm{Laplace}\left(0, \frac{\Delta f}{\epsilon} \right)$

## Examples: count statistic and average statistic

\begin{equation*}
\mathcal{M}_{L}({\bf{x}}, f(\cdot), \epsilon) = f({\bf{x}}) + (X_1^*, \cdots, X_k^*), 
\end{equation*}

- statistic $f$: How many rural CUs are there in this sample?
    - $\Delta f = 1$
    - $k = 1$ (i.e. statistic $f$ is $1-$dimension)
    - \textcolor{blue}{Discussion question}: What is the Laplace distribution the noise should be drawn from?
    
\pause

- Another statistic $f$: What is the average income of this sample?
    - $\Delta f = \frac{b - a}{n}$
    - $k = 1$ (i.e. statistic $f$ is $1-$dimension)
    - \textcolor{blue}{Discussion question}: What is the Laplace distribution the noise should be drawn from?

## The Laplace Mechanism preserves $\epsilon-$differential privacy

Proof: Let ${\bf{x}}, {\bf{y}} \in \mathbb{N}^{|\mathcal{X}|}$ and $\delta({\bf{x}}, {\bf{y}}) = 1$, and let $f(\cdot)$ be some function $f: \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathbb{R}^k$. Let $p_{{\bf{x}}}$ and $p_{{\bf{y}}}$ denote the probability density functions of $\mathcal{M}_{L}({\bf{x}}, f(\cdot), \epsilon)$ and $\mathcal{M}_{L}({\bf{y}}, f(\cdot), \epsilon)$. We compare the two at some arbitrary output  point $z \in \mathbb{R}^{k}$:

\begin{eqnarray*}
\frac{p_{\bf{x}}(z)}{p_{\bf{y}}(z)} 
&=& \mathop{\prod}_{i=1}^{k}\left(\frac{\exp\left(-\frac{|f({\bf{x}})_i - z_i|}{\Delta f / \epsilon}\right)}{\exp\left(-\frac{|f({\bf{y}})_i - z_i|}{\Delta f / \epsilon}\right)}\right) \\
&=& \mathop{\prod}_{i=1}^k \exp\left(\epsilon\frac{|f({\bf{y}})_i - z_i| - |f({\bf{x}})_i - z_i|}{\Delta f}\right) \\
&\leq& \mathop{\prod}_{i=1}^k \exp\left(\epsilon\frac{|(f({\bf{x}})_i - f({\bf{y}})_i)|}{\Delta f}\right)  \\
&=& \exp\left(\epsilon \frac{||f({\bf{x}}) - f({\bf{y}})||_1}{\Delta f}\right) \leq \exp(\epsilon)
\end{eqnarray*}


## CE example of a count statistic: step 1 

- Calculate the true count of rural CUs

```{r message=FALSE, size = "footnotesize"}
require(readr)
CEdata <- read_csv("CEdata.csv")
CEdata$s[CEdata$UrbanRural == 2] <- 1
CEdata$s[CEdata$UrbanRural == 1] <- 0
```

```{r message = FALSE, size = "footnotesize", warning = FALSE}
n_rural <- CEdata %>%
  summarize_at(vars(s), sum) %>%
  pull()
n_rural
```

## CE example of a count statistic: step 2

- Add Laplace noise to the true count

```{r message = FALSE, size = "footnotesize"}
Delta_f_count <- 1
```


```{r message = FALSE, size = "footnotesize"}
require(rmutil)
set.seed(123)
epsilon1 <- 0.1
rlaplace(1, n_rural, Delta_f_count/epsilon1) %>%
  round()
```

## CE example of a count statistic: step 2

```{r message = FALSE, size = "footnotesize"}
set.seed(123)
epsilon2 <- 1
rlaplace(1, n_rural, Delta_f_count/epsilon2) %>%
  round()
```

- With the true count of 337 rural CUs, we can see that smaller privacy budget adds more noise, $337 - 331 = 6$ (when $\epsilon = 0.1$) versus $337 - 336 = 1$ (when $\epsilon = 1$)

- These outcomes are in line with our previously discussed implications, that when fixing the sensitivity value, the added noise is negatively related to the privacy budget


# Properties of differential privacy

## Composition theorem

- Idea: taking together the independent use of an $\epsilon_1-$differentially private algorithm and an $\epsilon_2-$differentially private algorithm, results in $(\epsilon_1 + \epsilon_2)-$differential privacy

\pause

- Formally, let $\mathcal{M}_1: \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathcal{R}_1$ be an $\epsilon_1$-differentially private algorithm, and let $\mathcal{M}_2: \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathcal{R}_2$ be an $\epsilon_2$-differentially private algorithm. Then their combination, defined to be $\mathcal{M}_{1,2}: \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathcal{R}_1 \times \mathcal{R}_2$ by the mapping: $\mathcal{M}_{1,2}({\bf{x}}) = (\mathcal{M}_1({\bf{x}}), \mathcal{M}_2({\bf{x}}))$ is $(\epsilon_1 + \epsilon_2)-$differentially private

- Proof omitted; check out @DworkRoth2014

\pause

- A generalization: let $\mathcal{M}_i: \mathbb{N}^{|\mathcal{X}|} \rightarrow \mathcal{R}_i$ be an $\epsilon_i-$differentially private algorithm for $i \in [k]$. Then if $\mathcal{M}_{[k]}: \mathbb{N}^{|\mathcal{X}|} \rightarrow \prod_{i=1}^k \mathcal{R}_i$ is defined to be $\mathcal{M}_{[k]}({\bf{x}}) = (\mathcal{M}_1({\bf{x}}), \cdots, \mathcal{M}_k({\bf{x}}))$, then $\mathcal{M}_{|k|}$ is $(\sum_{i=1}^k \epsilon_i)-$differentially private

## Sequential composition

- If $m$ statistics are sent to the same dataset, the privacy budget needs to be divided by $m$:
\begin{equation}
\epsilon_{new} = \frac{\epsilon}{m}. 
\end{equation}

\pause

- Example: adding Laplace noise to four statistics
    1. What is the average income of this sample?
    2. What is the average expneditures of this sample?
    3. What is the variance of income in this sample?
    4. What is the variance of expenditures in this sample?

```{r message = FALSE, size = "footnotesize", eval = FALSE}
epsilon <- 0.1
m <- 4
epsilon_new <- epsilon/m
rlaplace(1, income_average, Delta_f_average_income/epsilon_new)
rlaplace(1, expenditures_average, Delta_f_average_exp/epsilon_new)
rlaplace(1, income_variance, Delta_f_variance_income/epsilon_new)
rlaplace(1, expenditures_variance, Delta_f_variance_exp/epsilon_new)
```

## Sequential composition

```{r message = FALSE, size = "footnotesize", eval = FALSE}
epsilon <- 0.1
m <- 4
epsilon_new <- epsilon/m
```
```{r message = FALSE, size = "footnotesize", eval = FALSE}
rlaplace(1, income_average, Delta_f_average_income/epsilon)
```
results in smaller noise (larger $\epsilon$, same $\Delta f$)

```{r message = FALSE, size = "footnotesize", eval = FALSE}
rlaplace(1, income_average, Delta_f_average_income/epsilon_new)
```
results in larger noise (smaller $\epsilon$, same $\Delta f$)

## Parallel composition

- If $m$ statistics are sent to the same database but \textcolor{red}{on non-overlapping subsets} of the dataset, the privacy budget does \textcolor{red}{not} need to be divded by $m$

\pause

- Examples: adding Laplace noise to two statistics
    1. What is the average income of rural CUs?
    2. What is the average income of urban CUs?
    
\begin{equation*}
\epsilon_{new} = \epsilon 
\end{equation*}

## Post-processing

- Dealing with contingency tables (e.g. counts of observations in each category of a categorical variable)

- The post-processing property indicates that for a contingency table with $c$ cells: 

\begin{equation}
\epsilon_{new} = \frac{\epsilon}{c-1}. 
\end{equation}

- This is because knowing the noisy counts of $c-1$ cells determines the count of the $c$-th cell

## Post-processing cont'd

- Examples: adding Laplace noise to six statistics (i.e. $c = 6$)
    1. How many CUs with reference person's race category as White are there in this sample?
    2. How many CUs with reference person's race category as Black are there in this sample?
    3. How many CUs with reference person's race category as Native American are there in this sample?
    4. How many CUs with reference person's race category as Asian are there in this sample?
    5. How many CUs with reference person's race category as Pacific Islander are there in this sample?
    6. How many CUs with reference person's race category as Multi-race are there in this sample?

```{r message = FALSE, size = "footnotesize", eval = FALSE}
epsilon <- 0.1
c <- 6
epsilon_new <- epsilon / (c-1) 
Race_6 <- n - Race_1 - Race_2 - Race_3 - Race_4 - Race_5
```

# Summary and References

## Summary

- The Laplace Mechanism
- Properties of differential privacy

\pause

- Next week:
    - Project presentations, 10-12min each team
    - Use presentation slides
    - Include a couple of slides on differential privacy methods for your data
    
    
## References {.allowframebreaks} 


